{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/IMDB-Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 35000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(data)\n",
    "dataset = dataset.train_test_split(test_size=0.3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35000/35000 [00:01<00:00, 33443.92 examples/s]\n",
      "Map: 100%|██████████| 15000/15000 [00:00<00:00, 34390.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "label2id = {'negative':0, 'positive':1}\n",
    "id2label = {0:'negative', 1:'positive'}\n",
    "dataset = dataset.map(lambda x: {'label': label2id[x['sentiment']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'I LOVE Jack\\'s jokes like \\'The cliché is...\\' or \"Over the top cliché guy, black, oily skin, kinda spooky...\". He is just hilarious! Daniel\\'s starting to catch up on him to! Good thing Jack\\'s not on the team anymore (in a way) or else it would have been sarcasm mania!!!!I just love all the plots (season 8, a little less, I have to admit), the characters are great, the actors are great, I\\'m starting to pick up facial expressions (and more) from Jack, Daniel and Teal\\'c...It just all theoretically possible and exciting...oops! Their I go again!!! Sorry, I\\'m also starting to pick up traits from Carter, and all of this is driving my parents NUTZ!!!!!!! Well, to conclude, I think it\\'s good for another three seasons or so, especially if they keep on packing the episodes with all this humor, drama, action and so forth!!!!!!!!!!!!!!!!',\n",
       " 'sentiment': 'positive',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35000/35000 [00:06<00:00, 5561.08 examples/s]\n",
      "Map: 100%|██████████| 15000/15000 [00:02<00:00, 6192.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model_ckpt = 'huawei-noah/TinyBERT_General_4L_312D'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
    "\n",
    "# tokenizer(dataset['train'][0]['review'])\n",
    "\n",
    "def tokenize(batch):\n",
    "    temp = tokenizer(batch['review'], padding=True, truncation=True, max_length=300)\n",
    "    return temp\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation functions & model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DownloadMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, \n",
    "                                                           num_labels=len(label2id), \n",
    "                                                           label2id=label2id, \n",
    "                                                           id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='train_dir',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy='epoch',\n",
    "    run_name=\"sentiment-analysis\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 500/3282 [04:16<22:48,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4644, 'grad_norm': 7.062708854675293, 'learning_rate': 1.695307739183425e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1000/3282 [08:23<18:49,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3592, 'grad_norm': 9.574926376342773, 'learning_rate': 1.3906154783668494e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 33%|███▎      | 1094/3282 [10:15<27:36,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31849968433380127, 'eval_accuracy': 0.869, 'eval_runtime': 63.5185, 'eval_samples_per_second': 236.152, 'eval_steps_per_second': 7.384, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 1500/3282 [13:40<15:08,  1.96it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3084, 'grad_norm': 11.188454627990723, 'learning_rate': 1.0859232175502743e-05, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2000/3282 [17:48<10:26,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2926, 'grad_norm': 18.35076332092285, 'learning_rate': 7.81230956733699e-06, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 2188/3282 [20:18<08:29,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2975030243396759, 'eval_accuracy': 0.8777333333333334, 'eval_runtime': 57.4561, 'eval_samples_per_second': 261.069, 'eval_steps_per_second': 8.163, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 2500/3282 [22:53<06:24,  2.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2729, 'grad_norm': 7.3425068855285645, 'learning_rate': 4.765386959171238e-06, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 3000/3282 [27:00<02:18,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2585, 'grad_norm': 8.516209602355957, 'learning_rate': 1.7184643510054846e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 3282/3282 [36:57<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28963857889175415, 'eval_accuracy': 0.8828, 'eval_runtime': 456.1483, 'eval_samples_per_second': 32.884, 'eval_steps_per_second': 1.028, 'epoch': 3.0}\n",
      "{'train_runtime': 2217.0625, 'train_samples_per_second': 47.36, 'train_steps_per_second': 1.48, 'train_loss': 0.3202110792644717, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3282, training_loss=0.3202110792644717, metrics={'train_runtime': 2217.0625, 'train_samples_per_second': 47.36, 'train_steps_per_second': 1.48, 'total_flos': 882184338000000.0, 'train_loss': 0.3202110792644717, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:56<00:00,  8.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.28963857889175415,\n",
       " 'eval_accuracy': 0.8828,\n",
       " 'eval_runtime': 56.8808,\n",
       " 'eval_samples_per_second': 263.709,\n",
       " 'eval_steps_per_second': 8.245,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('tinybert-movie-review-sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9880494475364685},\n",
       " {'label': 'positive', 'score': 0.9416130185127258},\n",
       " {'label': 'negative', 'score': 0.6329503059387207}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "data = ['this was a terrible film, i hated it', 'this film was ace!', 'not sure about this film but it might have been good']\n",
    "\n",
    "classifier = pipeline('text-classification', model='tinybert-movie-review-sentiment', device=device)\n",
    "\n",
    "classifier(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload movie sentiment analysis model to S3 instance (with boto3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reservations': [],\n",
       " 'ResponseMetadata': {'RequestId': '028b40ff-6def-4050-ac55-7f81bd0ab77a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '028b40ff-6def-4050-ac55-7f81bd0ab77a',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '219',\n",
       "   'date': 'Fri, 10 Jan 2025 17:04:16 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ec2 = boto3.client('ec2', region_name='us-east-1')\n",
    "\n",
    "ec2.describe_instances()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this once - creates and saves key pair\n",
    "#resp = ec2.create_key_pair(KeyName='boomer')\n",
    "file = open('creds/boomer.pem', 'w')\n",
    "file.write(resp['KeyMaterial'])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KeyFingerprint': 'bf:7c:e5:3f:81:dd:8d:4c:99:ce:f7:f1:6d:e6:61:7d:e9:3d:36:46',\n",
       " 'KeyMaterial': '-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEA6aStg0Puo+550ROjZ3ryUd9yASMpaDFET+rY5nd1LBa62acy\\nBEhXYDy2fMBRmdRoyF8RQ+OKEW4MaxjO2AmPvvKEErTtOE5PxmINGgaEKhqsHm4e\\nZkr33MH/sUJL7R+qmGeUtGoFQV5Rya05nyt5dHGmibtKx67bNwetVuLenHnhSFmw\\nTMy4PyXq7qmSHpU7nwucxG5oCJ2eWsKG7E0pcdnIUOMYplCH/NBgUxD13k0Dy1+/\\nCYB6VrDjIQ57WlLsOM/Ql5eGSckEH+vSuWIUIx5LknP2FRTEa7ZuAaf7pLYxIgmu\\n3bkZRdsy0kcRMCijZ2c9AgnSIJnTUmkdFOpQUQIDAQABAoIBAQCkV5M868GmSY4i\\nBGBB33cnI7a7GhJ8GXtlg1mB8rDWjD5t7m7+GCxtowbxhQ1g2MnDdytbx2dMj03o\\n3xBPYZpcw5Um22Co5Fy0vC9fCQpZ210KIob7iOwDuemys2FYr5d9kA5HQPPlYQTC\\niTgov5m00GRGKRmWj2XetWW14eqXwMMVrlpWcgFBB5a0KIR8bAvP72M6fdse6CGx\\ng7mj0Ebvj+P/49Zh0DB12IL7oGxIRcCPSe0/E0KV3Z2ZWyVwPkjDLOsJ7YLcL3Ch\\nx2nH/LEiMPaCcfA1yUA2XmOZzx60eRueaWAZ0zo6hAjCGkoe/+a3rtpB0wC84hke\\nPqny9TABAoGBAPnVtzBJCEXgxkxcDcCq2pHCAqYn1Lmw5Oknrd1jx0yc45gUdK8K\\nIhjdNIJ0GsjsLGofNZNeiwLxGYPprGtbYg7v1HlpqSN1uAyUWt+aTA6LLBKFVCTE\\nVC1xnFWSMEAiDl4WSgI0TTxTv3xFFRGmrwkjkScNimrIZKato6KA1NzRAoGBAO9o\\nrNRJ2WVS1DKVO/O46+BXnSHfjpk/JXkdJeeW4mlETW8++cSINU7CFZ1RTyQtv5Eg\\nKUHA7NxLrZalFJxMzQdCtU+nyqmMAP2rWoG5gDf1NY8wBO+EKyXsWTF1N43/QJvQ\\niHLgsT8s6sqyzuFO7lvKrMTWq0Le3JCGYm1zzRuBAoGAQqDSeBgiErC9ccPjDw0B\\nuXmqRzG8M8GPavbgEXj4v9/fesGJ1Ny49zSXOmtIcWk69xpXqXO/UwuFqH57My5t\\n2lnvqmmZaBGPAhvWmGeH/SD0ogPYyu1pHa186f1QzOnINyNunWPhbUNQgA3Ubp6r\\nc55+qZGc5pmG7kTErSP6oOECgYAPxShlT3wHhZ4+ur/ZPRwkigDqw0wkYhl40ee2\\nSqUdZAdpxY80V/iS+Ivt8fYxnuXYjHLLRwcTN9T2cGdcKF71FHrXBWl/I57JFul+\\nVBbTGM7vYK1ijaU9+USi0mLXcrHx0Zm7X3uteqr4sTCZfNaMq1wYFz/uxrlmt8Ny\\nDEe9gQKBgQC++wQ94vWy2bhOSgjBLvkZ0p2vGO5PG8VayqnwFIIC5SoC+BkDj2Bk\\nAPYpLc0sAJY7ErZ65h3A9JzQYeiJ9vgbR9/DMeRx5HHSdewW56+DbAzvqPTURuPC\\nrVLWhPuBBmUfQL2hK/2507vzN1etmRzv3Y3i1/nu7Cr3LTpUGkY+LQ==\\n-----END RSA PRIVATE KEY-----',\n",
       " 'KeyName': 'boomer',\n",
       " 'KeyPairId': 'key-0ae9e9067677507f9',\n",
       " 'ResponseMetadata': {'RequestId': '2a8f6292-dd7d-4317-a99f-795fcf1342ce',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2a8f6292-dd7d-4317-a99f-795fcf1342ce',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'accept-encoding',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '2060',\n",
       "   'date': 'Fri, 10 Jan 2025 16:52:43 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket is created\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'movie-sentiment-analysis'\n",
    "\n",
    "def create_bucket(bucket_name):\n",
    "    response = s3.list_buckets()\n",
    "    buckets = [buck['Name'] for buck in response['Buckets']]\n",
    "    if bucket_name not in buckets:\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "        print(\"Bucket is created\")\n",
    "\n",
    "    else:\n",
    "        print(\"Bucket already exists in your account!!! Feel free to use it.\")\n",
    "\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinybert-movie-review-sentiment/model.safetensors movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/model.safetensors\n",
      "tinybert-movie-review-sentiment/tokenizer_config.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/tokenizer_config.json\n",
      "tinybert-movie-review-sentiment/special_tokens_map.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/special_tokens_map.json\n",
      "tinybert-movie-review-sentiment/config.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/config.json\n",
      "tinybert-movie-review-sentiment/tokenizer.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/tokenizer.json\n",
      "tinybert-movie-review-sentiment/training_args.bin movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/training_args.bin\n",
      "tinybert-movie-review-sentiment/vocab.txt movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# upload model folder to s3 bucket ml-models/tinybert-sentiment-analysis\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "#s3 = boto3.client('s3')\n",
    "\n",
    "def upload_directory(directory_path, s3_prefix):\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file).replace(\"\\\\\", \"/\")\n",
    "            relpath = os.path.relpath(file_path, directory_path)\n",
    "            s3_key = os.path.join(s3_prefix, relpath).replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            # s3.upload_file(file_path, bucket_name, s3_key)\n",
    "            print(file_path, bucket_name, s3_key)\n",
    "\n",
    "\n",
    "upload_directory('tinybert-movie-review-sentiment', 'ml-models/tinybert-sentiment-analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinybert-movie-review-sentiment/model.safetensors movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/model.safetensors\n",
      "tinybert-movie-review-sentiment/tokenizer_config.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/tokenizer_config.json\n",
      "tinybert-movie-review-sentiment/special_tokens_map.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/special_tokens_map.json\n",
      "tinybert-movie-review-sentiment/config.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/config.json\n",
      "tinybert-movie-review-sentiment/tokenizer.json movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/tokenizer.json\n",
      "tinybert-movie-review-sentiment/training_args.bin movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/training_args.bin\n",
      "tinybert-movie-review-sentiment/vocab.txt movie-sentiment-analysis ml-models/tinybert-sentiment-analysis/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# Recreate the 'upload_directory' function with pathlib\n",
    "#\n",
    "#  THIS FUNCTION DOES THE SAME AS THE ONE ABOVE, BUT USES PATHLIB INSTEAD OF OS\n",
    "#\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# s3_prefix = Path('ml-models/tinybert-sentiment-analysis')\n",
    "\n",
    "def upload_directory_pathlib(directory_path, s3_prefix):\n",
    "    directory = Path(directory_path)\n",
    "    for file_path in directory.rglob(\"*\"):\n",
    "        if file_path.is_file():\n",
    "            relpath = file_path.relative_to(directory).as_posix()\n",
    "            s3_key = f\"{s3_prefix}/{relpath}\"\n",
    "\n",
    "            #s3.upload_file(file_path, bucket_name, s3_key)\n",
    "            print(file_path, bucket_name, s3_key)\n",
    "\n",
    "upload_directory_pathlib('tinybert-movie-review-sentiment', 'ml-models/tinybert-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
